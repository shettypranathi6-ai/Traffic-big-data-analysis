# ğŸš¦ Real-Time Traffic Analysis with Apache Kafka & Streamlit

A real-time Big Data pipeline that monitors traffic conditions at specific junctions (currently configured for **Silk Board Junction, Bangalore**). The system fetches live traffic flow data from the TomTom API, streams it through **Apache Kafka**, and visualizes real-time metrics and trends using a **Streamlit** dashboard.

## ğŸ— Architecture



The project follows a Producer-Consumer architecture:
1.  **Data Source:** **TomTom Traffic API** provides real-time speed and congestion data.
2.  **Producer:** A Python script (`producer.py`) polls the API every 60 seconds and pushes JSON data to a **Kafka Topic** (`traffic_data`).
3.  **Message Broker:** **Apache Kafka** (managed via Zookeeper) acts as the high-throughput buffer for the data stream.
4.  **Consumer/Dashboard:** **Streamlit** (`dashboard.py`) consumes messages from Kafka, processes the data, and updates a live interactive dashboard.

## ğŸ›  Tech Stack

* **Language:** Python 3.9
* **Message Broker:** Apache Kafka & Zookeeper
* **Visualization:** Streamlit, Plotly Express
* **Containerization:** Docker & Docker Compose
* **Data Processing:** Pandas
* **External API:** TomTom Maps API

## ğŸ“‚ Project Structure

```text
TrafficBigData/
â”œâ”€â”€ dashboard.py         # Streamlit frontend (Kafka Consumer)
â”œâ”€â”€ producer.py          # Data ingestion script (Kafka Producer)
â”œâ”€â”€ docker-compose.yml   # Orchestration for Kafka, Zookeeper, and App
â”œâ”€â”€ Dockerfile           # Environment definition for the Python app
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .env                 # API Keys (Not included in repo)
â””â”€â”€ README.md            # Project documentation
